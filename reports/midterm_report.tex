\documentclass[12pt]{article}
	\usepackage{amsmath}
	\usepackage{amssymb}
	\usepackage{fancyhdr}
	\usepackage{float}
	\usepackage{graphicx}
	\usepackage{cite}

	\oddsidemargin0cm
	\topmargin-2cm     %I recommend adding these three lines to increase the 
	\textwidth16.5cm   %amount of usable space on the page (and save trees)
	\textheight23.5cm  

\newcommand{\myname}{Evan Palmer, Titouan Rigoudy}
\newcommand{\myandrew}{esp@andrew, trigoudy@andrew}
\newcommand{\myhwnum}{1}
\newcommand{\problemnum}{1}
\newcommand{\thedate}{\today}
\DeclareMathOperator*{\argmax}{arg\,max}
%Page header
	\setlength{\parindent}{0pt}
	\setlength{\parskip}{5pt plus 1pt}
	 
	\pagestyle{fancyplain}
	\lhead{\fancyplain{}{\textbf{Midway report}}}      % Note the different brackets!
	\rhead{\fancyplain{}{\myname\\ \myandrew}}
	\chead{\fancyplain{}{10-701}}
\begin{document}
%Title
	\medskip    
	\thispagestyle{plain}
	\begin{center}                 
	{\LARGE Finding The Best Critic For You} \\
	\medskip
	Machine Learning Midway Report \\
	\smallskip
	\myname \\
	\myandrew \\
	\thedate \\
	\end{center}
	\vspace{0.5cm}

\section{Introduction}

\section{Obtaining the data}

	We found two sites public API where we could access movie information and reviews: Rotten Tomatoes and Metacritic. We wanted to find movies which many critics and users would likely have seen and rated. Unfortunately neither of these sites had a mechanism for retrieving the most reviewed films. 

	To solve this problem we obtained a list of the most rated films from IMBD. We sorted this list by the number of ratings, and chose the five thousand most rated movies. 

	We then used the Metacritic and Rotten Tomatoes APIs to retrieve information, reviews, and anything else that was available for each of these movies.

\section{Data descriptions}

\subsection{Rotten tomatoes}

	The data we retrieved from Rotten tomatoes included approximately five hundred thousand reviews by about four thousand unique critics about four thousand movies.

	The Rotten Tomatoes data is very promising. Movies are reviewed by on average about twenty critics which are designated as \textit{top critics}, and by about one hundred critics with no top designation. Furthermore, these distributions are fairly uniform as shown by the Histogram in Figure \ref{fig:r_mov}. This means that we have a large number of movies with many critic reviews.

	Critics have, on average about twenty reviews where they are designated as \textit{top critics}, and about seventy where they receive no designation. This might seem surprising as we would expect top critics to review more things. Really this reflects an interesting naming convention by Rotten Tomatoes. Though a critic may be designated as a \textit{top critic} for a particular movie, this designation may change from movie to movie. One notable exception is Rodger Ebert who was designated as a top critic for $2862$ movies! These distributions are more skewed by critics, like Ebert, who have reviewed many movies as seen in Figure \ref{fig:r_crit}. However, there are still many critics who have reviewed a sizable number of films.

	Rotten Tomatoes differentiates between individual critics and the publication which they write for. If we look at the same things we looked at for critics, but group them by publication, we find a higher mean number of films reviewed. This could be useful as publications, like critics, may maintain a distinct taste profile.

	\begin{table}[H]
	 \centering
	 \caption{Distribution of number of reviews per critic for movies on rotten tomatoes}
	 \begin{tabular}{ l | c | c | c | c }
	 \hline
	 &  Min & Max & Mean & Std Dev  \\
	 \hline
	 Top Critcs & 0 & 56 & 22.41 & 16.06 \\
	 Other Critics & 0 & 316 & 92.24 & 68.12 \\
	 \hline
	 \end{tabular}
	 \end{table}

	\begin{figure}[H]
	    \centering
	    \includegraphics[width=0.48\textwidth]{plots/plot_r_mov_top.png}
	    \includegraphics[width=0.48\textwidth]{plots/plot_r_mov_oth.png}
	    \caption{INSERT TITLE}
	    \label{fig:r_mov} 
	\end{figure}


	\begin{table}[H]
	 \centering
	 \caption{Distribution of number of reviewed movies per critic on rotten tomatoes} 
	 \begin{tabular}{ l | c | c | c | c }
	 \hline
	 &  Min & Max & Mean & Std Dev  \\
	 \hline
	 Top Critcs & 0 & 2862 & 21.79 & 124.96 \\
	 Other Critics & 0 & 2634 & 68.16 & 224.77 \\
	 \hline
	 \end{tabular}
	 \end{table}

	\begin{figure}[H]
	    \centering
	    \includegraphics[width=0.48\textwidth]{plots/plot_r_crit_top.png}
	    \includegraphics[width=0.48\textwidth]{plots/plot_r_crit_oth.png}
	    \caption{INSERT TITLE}
	    \label{fig:r_crit}
	\end{figure}


	\begin{table}[H]
	 \centering
	 \caption{Distribution of number of reviewed movies per publication on rotten tomatoes} 
	 \begin{tabular}{ l | c | c | c | c }
	 \hline
	 &  Min & Max & Mean & Std Dev  \\
	 \hline
	 Top Publications & 0 & 4135 & 97.22 & 454.15 \\
	 Other Publications & 0 & 3224 & 297.78 & 520.28 \\
	 \hline
	 \end{tabular}
	 \end{table}

	 \begin{figure}[H]
	    \centering
	    \includegraphics[width=0.48\textwidth]{plots/plot_r_pub_top.png}
	    \includegraphics[width=0.48\textwidth]{plots/plot_r_pub_oth.png}
	    \caption{INSERT TITLE}
	    \label{fig:r_pub}
	\end{figure}

\subsection{Metacritic}

	The Metacritic dataset contains $3228$ movies with $152622$ reviews from $69$ unique critics and $20183$ unique users. Of these reviews $80332$ were written by users, and $69590$ were written by critics


	Films were somewhat harder to retrieve from Metacritic than Rotten Tomatoes. The indexing in the Metacritic search function seemed to rely mostly on attributes other than title, as a result, many queries resulted in the wrong movie. For instance when searching for \textit{Batman Begins} we instead received \textit{The Dark Knight}. This is most likely due to \textit{Batman} being very closely related to \textit{The Dark Knight}, and the film \textit{Batman Begins} being significantly less popular. Due to problems like this we were unable to retrieve as many films as with Rotten Tomatoes.

	In contrast to rotten tomatoes, Metacritic draws from a very small pool of critics. This is partially because what Metacritic describes as \textit{critics} Rotten Tomatoes describes as \textit{publications}. On average each of these critics has reviewed twelve hundred films. This means that for each critic we have a fairly large overlap.

	The films also have about twenty one user reviews on average. This provides us with real user data which is something which we did not obtain from Rotten Tomatoes. As seen in Figure \ref{fig:m_crit}, Approximately twenty percent of movies have at least twenty user reviews, giving us a reasonable number of movies with reviews.

	Unfortunately, there are very few users who review many movies. From Figure \ref{fig:m_crit} we can see that reviewing more than twenty films occurs at approximately the ninety-eighth percentile, giving us about forty users.

	\begin{table}[H]
	 \centering
	 \caption{Distribution of number of reviews by users and critics for movies on Metacritic}

	 \begin{tabular}{ l | c | c | c | c }
	 \hline 
	 &  Min & Max & Mean & Std Dev  \\
	 \hline
	 Critics with reviews & 0 & 49 & 25.72 & 10.83 \\
	 Users with reviews & 0 & 842 & 21.56 & 50.05 \\
	 \hline
	 \end{tabular}
	 \end{table}

	 \begin{figure}[H]
	    \centering
	    \includegraphics[width=0.48\textwidth]{plots/plot_m_mov_top.png}
	    \includegraphics[width=0.48\textwidth]{plots/plot_m_mov_usr.png}
	    \caption{Cumulative histograms of critic and user reviews per movie for movies on Metacritic}
	    \label{fig:m_mov}
	\end{figure}


	\begin{table}[H]
	\centering
	 \caption{Distribution of number of reviewed movies by users and critics on Metacritic}

	 \begin{tabular}{ l | c | c | c | c }
	 \hline
	 &  Min & Max & Mean & Std Dev  \\
	 \hline
	 Reviews per critic & 56 & 3445 & 1203.36 & 912.50 \\
	 Reviews per user & 1 & 536 & 3.45 & 14.55 \\
	 \hline
	 \end{tabular}
	 \end{table}


	 \begin{figure}[H]
	    \centering
	    \includegraphics[width=0.48\textwidth]{plots/plot_m_crit_top.png}
	    \includegraphics[width=0.48\textwidth]{plots/plot_m_crit_usr.png}
	    \caption{Cumulative histograms }
	    \label{fig:m_crit}
	\end{figure}

\section{Matrix factorization}

	As our baseline approach we used stochastic matrix factorization. 


	\begin{figure}[H]
	\centering
	\includegraphics[width=0.48\textwidth]{plots/test-i100d1l0.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d1l1.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d1l3.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d1l10.png}
	\caption{Mean squared training and test error over 100 iterations in the stochastic matrix factorization model. Stochastic gradient descent was done using a step size of 0.02. The learned critic matrix was count(critics) by 1, and the learned movie matrix was 1 by count(movies).}
	\label{fig:1}
	\end{figure}


	\begin{figure}[H]
	\centering
	\includegraphics[width=0.48\textwidth]{plots/test-i100d10l0.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d10l1.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d10l3.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d10l10.png}
	\caption{Mean squared training and test error over 100 iterations in the stochastic matrix factorization model. Stochastic gradient descent was done using a step size of 0.02. The learned critic matrix was count(critics) by 10, and the learned movie matrix was 10 by count(movies).}
	\label{fig:10}
	\end{figure}


	\begin{figure}[H]
	\centering
	\includegraphics[width=0.48\textwidth]{plots/test-i100d25l0.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d25l1.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d25l3.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d25l10.png}
	\caption{Mean squared training and test error over 100 iterations in the stochastic matrix factorization model. Stochastic gradient descent was done using a step size of 0.02. The learned critic matrix was count(critics) by 25, and the learned movie matrix was 25 by count(movies).}
	\label{fig:25}
	\end{figure}


	\begin{figure}[H]
	\centering
	\includegraphics[width=0.48\textwidth]{plots/test-i100d40l0.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d40l1.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d40l3.png}
	\includegraphics[width=0.48\textwidth]{plots/test-i100d40l10.png}
	\caption{Mean squared training and test error over 100 iterations in the stochastic matrix factorization model. Stochastic gradient descent was done using a step size of 0.02. The learned critic matrix was count(critics) by 40, and the learned movie matrix was 40 by count(movies).}
	\label{fig:40}
	\end{figure}


\section{Recommender Systems}

What we are trying to do here is to recommend a critic to a user based on past
critic ratings and past user ratings. In other words, we are trying to build
a recommender system.

Formally, a recommender system takes a set of users $U = \{u_1, ..., u_N\}$, a
set of items $I = \{i_1, ..., i_M\}$, and a sparse matrix of ratings
$R$ of size $N \times M$. If $R_{k,l} > 0$, then user $u_k$ has given item $i_l$ a rating of $R_{k,l}$. A zero rating signifies that the
user has not rated the item. The goal of the system is then to predict the rating that a user would give to an item he has not yet rated. The system can
then recommend any number of items with highest predicted rating.

As described in \cite{Survey05}, recommender systems can be divided in three broad categories: content-based systems, collaborative systems and hybrid systems. 

Content-based recommender systems try to identify item features in order to compare items and recommend similar items to those that the user has rated highly in the past.  For example, if a user consistently rates history books highly, the system can recommend other history books.

Collaborative recommender systems do not try to extract features from the items
to be recommended. Instead, such systems will recommend items that users with similar tastes have rated highly in the past.

Hybrid recommender systems try to combine both approaches in order to improve recommendations.

\section{Further work}


\bibliography{bibliography}{}
\bibliographystyle{plain}

\end{document}