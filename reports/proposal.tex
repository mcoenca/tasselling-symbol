% You should title the file with a .tex extension (hw1.tex, for example)
\documentclass[12pt]{article}

	\usepackage{amsmath}
	\usepackage{amssymb}
	\usepackage{fancyhdr}

	\oddsidemargin0cm
	\topmargin-2cm     %I recommend adding these three lines to increase the 
	\textwidth16.5cm   %amount of usable space on the page (and save trees)
	\textheight23.5cm  

\newcommand{\myname}{Evan Palmer, Titouan Rigoudy}
\newcommand{\myandrew}{esp@andrew.cmu.edu, trigoudy@andrew.cmu.edu}
\newcommand{\myhwnum}{1}
\newcommand{\problemnum}{1}
\newcommand{\thedate}{\today}
\DeclareMathOperator*{\argmax}{arg\,max}
%Page header
	\setlength{\parindent}{0pt}
	\setlength{\parskip}{5pt plus 1pt}
	 
	\pagestyle{fancyplain}
	\lhead{\fancyplain{}{\textbf{HW\myhwnum}}}      % Note the different brackets!
	\rhead{\fancyplain{}{\myname\\ \myandrew}}
	\chead{\fancyplain{}{15-451 }}
\begin{document}
%Title
	\medskip    
	\thispagestyle{plain}
	\begin{center}                 
	{\LARGE Finding The Best Critic For You} \\
	\medskip
	Machine Learning Project Proposal \\
	\smallskip
	\myname \\
	\myandrew \\
	\thedate \\
	\end{center}
	\vspace{0.5cm}

As Netflix and others have noticed, it is quite difficult to accurately predict which movies a user will enjoy. We are interested, not so much in predicting which movies a user will be interested in, but which critics their taste most closely aligns with. There are many critics on the Internet with wildly varying tastes, and finding which ones to listen to can be a daunting task.

Thankfully, the Internet Movie Database (imdb.com) provides their databases to the public in an easy to download format. This should provide comprehensive movie information along with user ratings and reviews. For critics' ratings and reviews, we can use Rotten Tomatoes' public API along with screen scraping.  

As a first step we plan to simply use numerical ratings. Given a user and her ratings for a given list of movies, we would like to determine which critics her tastes most closely align with.

After we complete a simple classification system based on numerical ratings we would like to add more features. Some additional features which would be interesting would be genre, director/actors, box-office, and other users' ratings. Barring unforeseen roadblocks we would like to have this system working by the midway report.

Comparing reviews in a more sophisticated way than looking only at the star ratings makes for an interesting problem. We would like to see if there are useful features which can be extracted from the text of the reviews. For instance, if a critic and a user both tend to mention the same characters, or write reviews of similar length when they agree, can we use this information?

There are lots of possible relationships to explore here. Longer reviews might be more indicative of the users' taste since they possibly indicate a stronger opinion. Similar adjectives, or in general similar vocabulary in two reviews might suggest a stronger correlation. In general, we expect that sentiment analysis techniques could be applied to compare reviews in a useful way.

In our brief review of the literature, we haven't seen much work using NLP to compare reviews (though we may have missed such work). If this is indeed the case, and we are able to get useful results, a stretch goal could be publication. 

In any case we would consider our project successful if we can improve our basic model by using NLP to compare reviews. To test our performance of our prediction, we can train our model on films before 2012, and then test on films after this date.

\end{document}